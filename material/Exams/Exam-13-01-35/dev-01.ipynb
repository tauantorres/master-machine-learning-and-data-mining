{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 1000 rows and 17 columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>F00</th>\n",
       "      <th>F01</th>\n",
       "      <th>F02</th>\n",
       "      <th>F03</th>\n",
       "      <th>F04</th>\n",
       "      <th>F05</th>\n",
       "      <th>F06</th>\n",
       "      <th>F07</th>\n",
       "      <th>F08</th>\n",
       "      <th>F09</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.430770</td>\n",
       "      <td>-0.609499</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>-0.244014</td>\n",
       "      <td>1.515603</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>0.950208</td>\n",
       "      <td>-0.533577</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>-1.188635</td>\n",
       "      <td>0.117022</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.078747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926832</td>\n",
       "      <td>-1.232067</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-2.147707</td>\n",
       "      <td>-0.907709</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-3.431166</td>\n",
       "      <td>-0.851632</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-0.614415</td>\n",
       "      <td>-0.641244</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.277881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.488724</td>\n",
       "      <td>1.732096</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>2.564819</td>\n",
       "      <td>-0.744121</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>-0.298340</td>\n",
       "      <td>-0.276540</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>1.395205</td>\n",
       "      <td>-0.290211</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>1.070634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  F00       F01       F02       F03       F04       F05  \\\n",
       "0           0  NaN  0.430770 -0.609499  0.153154 -0.244014  1.515603   \n",
       "1           1  NaN  0.926832 -1.232067 -2.397645 -2.147707 -0.907709   \n",
       "2           2  NaN  1.488724  1.732096 -0.247872  2.564819 -0.744121   \n",
       "\n",
       "        F06       F07       F08       F09       F10       F11  F12 F13  \\\n",
       "0  0.153154  0.950208 -0.533577  0.153154 -1.188635  0.117022    0   D   \n",
       "1 -2.397645 -3.431166 -0.851632 -2.397645 -0.614415 -0.641244    0   C   \n",
       "2 -0.247872 -0.298340 -0.276540 -0.247872  1.395205 -0.290211    6   B   \n",
       "\n",
       "        F14  class  \n",
       "0  0.078747      1  \n",
       "1 -0.277881      1  \n",
       "2  1.070634      0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 01:\n",
    "\n",
    "# 1.1 Load the file:\n",
    "path = \"data.csv\"\n",
    "df_raw = pd.read_csv(filepath_or_buffer=path)\n",
    "\n",
    "# 1.2 Show the sizes:\n",
    "rows, column = df_raw.shape\n",
    "print(f\"The data has {rows} rows and {column} columns.\")\n",
    "\n",
    "# 1.3 Show some data:\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 17 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  1000 non-null   int64  \n",
      " 1   F00         50 non-null     float64\n",
      " 2   F01         1000 non-null   float64\n",
      " 3   F02         1000 non-null   float64\n",
      " 4   F03         1000 non-null   float64\n",
      " 5   F04         1000 non-null   float64\n",
      " 6   F05         1000 non-null   float64\n",
      " 7   F06         1000 non-null   float64\n",
      " 8   F07         1000 non-null   float64\n",
      " 9   F08         1000 non-null   float64\n",
      " 10  F09         1000 non-null   float64\n",
      " 11  F10         1000 non-null   float64\n",
      " 12  F11         1000 non-null   float64\n",
      " 13  F12         1000 non-null   int64  \n",
      " 14  F13         1000 non-null   object \n",
      " 15  F14         1000 non-null   float64\n",
      " 16  class       1000 non-null   int64  \n",
      "dtypes: float64(13), int64(3), object(1)\n",
      "memory usage: 132.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the columns 0 and 1 can be dropped. \n",
    "- The column 0 is just the index of the rowns;\n",
    "- The column 1 has only 50 non-null numbers out of 1000 rowns, therefore, they won't be helpful in our analyzes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns Name: ['Unnamed: 0', 'F00', 'F01', 'F02', 'F03', 'F04', 'F05', 'F06', 'F07', 'F08', 'F09', 'F10', 'F11', 'F12', 'F13', 'F14', 'class']\n"
     ]
    }
   ],
   "source": [
    "columsn_names = df_raw.columns\n",
    "print(f\"Columns Name: {list(columsn_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F01</th>\n",
       "      <th>F02</th>\n",
       "      <th>F03</th>\n",
       "      <th>F04</th>\n",
       "      <th>F05</th>\n",
       "      <th>F06</th>\n",
       "      <th>F07</th>\n",
       "      <th>F08</th>\n",
       "      <th>F09</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.430770</td>\n",
       "      <td>-0.609499</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>-0.244014</td>\n",
       "      <td>1.515603</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>0.950208</td>\n",
       "      <td>-0.533577</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>-1.188635</td>\n",
       "      <td>0.117022</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.078747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.926832</td>\n",
       "      <td>-1.232067</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-2.147707</td>\n",
       "      <td>-0.907709</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-3.431166</td>\n",
       "      <td>-0.851632</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-0.614415</td>\n",
       "      <td>-0.641244</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.277881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.488724</td>\n",
       "      <td>1.732096</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>2.564819</td>\n",
       "      <td>-0.744121</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>-0.298340</td>\n",
       "      <td>-0.276540</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>1.395205</td>\n",
       "      <td>-0.290211</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>1.070634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        F01       F02       F03       F04       F05       F06       F07  \\\n",
       "0  0.430770 -0.609499  0.153154 -0.244014  1.515603  0.153154  0.950208   \n",
       "1  0.926832 -1.232067 -2.397645 -2.147707 -0.907709 -2.397645 -3.431166   \n",
       "2  1.488724  1.732096 -0.247872  2.564819 -0.744121 -0.247872 -0.298340   \n",
       "\n",
       "        F08       F09       F10       F11  F12 F13       F14  class  \n",
       "0 -0.533577  0.153154 -1.188635  0.117022    0   D  0.078747      1  \n",
       "1 -0.851632 -2.397645 -0.614415 -0.641244    0   C -0.277881      1  \n",
       "2 -0.276540 -0.247872  1.395205 -0.290211    6   B  1.070634      0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = df_raw.drop(labels=[\"Unnamed: 0\", \"F00\"], axis=1)\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   F01     1000 non-null   float64\n",
      " 1   F02     1000 non-null   float64\n",
      " 2   F03     1000 non-null   float64\n",
      " 3   F04     1000 non-null   float64\n",
      " 4   F05     1000 non-null   float64\n",
      " 5   F06     1000 non-null   float64\n",
      " 6   F07     1000 non-null   float64\n",
      " 7   F08     1000 non-null   float64\n",
      " 8   F09     1000 non-null   float64\n",
      " 9   F10     1000 non-null   float64\n",
      " 10  F11     1000 non-null   float64\n",
      " 11  F12     1000 non-null   int64  \n",
      " 12  F13     1000 non-null   object \n",
      " 13  F14     1000 non-null   float64\n",
      " 14  class   1000 non-null   int64  \n",
      "dtypes: float64(12), int64(2), object(1)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 02:\n",
    "\n",
    "df = df_raw.copy()\n",
    "\n",
    "for column_name in df:\n",
    "    \n",
    "    missing_feature = df[column_name].isnull()\n",
    "    qnt_missing_feature = missing_feature.sum()\n",
    "\n",
    "    if qnt_missing_feature > 0:\n",
    "\n",
    "        print(f\"Missing feature {column_name} ({df[column_name].dtype}): {qnt_missing_feature}\")\n",
    "\n",
    "        if df[column_name].dtype not in [int, float]:\n",
    "            df[column_name] = df[column_name].fillna(value=\"unknown\")\n",
    "\n",
    "        else:\n",
    "            mean = df[column_name].mean()\n",
    "            df[column_name] = df[column_name].fillna(value=mean)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F01</th>\n",
       "      <th>F02</th>\n",
       "      <th>F03</th>\n",
       "      <th>F04</th>\n",
       "      <th>F05</th>\n",
       "      <th>F06</th>\n",
       "      <th>F07</th>\n",
       "      <th>F08</th>\n",
       "      <th>F09</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.430770</td>\n",
       "      <td>-0.609499</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>-0.244014</td>\n",
       "      <td>1.515603</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>0.950208</td>\n",
       "      <td>-0.533577</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>-1.188635</td>\n",
       "      <td>0.117022</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.078747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.926832</td>\n",
       "      <td>-1.232067</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-2.147707</td>\n",
       "      <td>-0.907709</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-3.431166</td>\n",
       "      <td>-0.851632</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-0.614415</td>\n",
       "      <td>-0.641244</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.277881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.488724</td>\n",
       "      <td>1.732096</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>2.564819</td>\n",
       "      <td>-0.744121</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>-0.298340</td>\n",
       "      <td>-0.276540</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>1.395205</td>\n",
       "      <td>-0.290211</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "      <td>1.070634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        F01       F02       F03       F04       F05       F06       F07  \\\n",
       "0  0.430770 -0.609499  0.153154 -0.244014  1.515603  0.153154  0.950208   \n",
       "1  0.926832 -1.232067 -2.397645 -2.147707 -0.907709 -2.397645 -3.431166   \n",
       "2  1.488724  1.732096 -0.247872  2.564819 -0.744121 -0.247872 -0.298340   \n",
       "\n",
       "        F08       F09       F10       F11  F12 F13       F14  class  \n",
       "0 -0.533577  0.153154 -1.188635  0.117022    0   D  0.078747      1  \n",
       "1 -0.851632 -2.397645 -0.614415 -0.641244    0   C -0.277881      1  \n",
       "2 -0.276540 -0.247872  1.395205 -0.290211    6   B  1.070634      0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F01</th>\n",
       "      <th>F02</th>\n",
       "      <th>F03</th>\n",
       "      <th>F04</th>\n",
       "      <th>F05</th>\n",
       "      <th>F06</th>\n",
       "      <th>F07</th>\n",
       "      <th>F08</th>\n",
       "      <th>F09</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F14</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.464389</td>\n",
       "      <td>0.024135</td>\n",
       "      <td>-0.090224</td>\n",
       "      <td>0.597048</td>\n",
       "      <td>-0.019323</td>\n",
       "      <td>-0.090224</td>\n",
       "      <td>-0.018502</td>\n",
       "      <td>0.017389</td>\n",
       "      <td>-0.090224</td>\n",
       "      <td>0.200876</td>\n",
       "      <td>0.019299</td>\n",
       "      <td>2.481000</td>\n",
       "      <td>0.163715</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.253621</td>\n",
       "      <td>0.981668</td>\n",
       "      <td>1.047949</td>\n",
       "      <td>1.525925</td>\n",
       "      <td>1.007243</td>\n",
       "      <td>1.047949</td>\n",
       "      <td>1.493104</td>\n",
       "      <td>0.995193</td>\n",
       "      <td>1.047949</td>\n",
       "      <td>1.649333</td>\n",
       "      <td>1.015434</td>\n",
       "      <td>2.280974</td>\n",
       "      <td>0.534304</td>\n",
       "      <td>0.596935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.839055</td>\n",
       "      <td>-3.678544</td>\n",
       "      <td>-2.900095</td>\n",
       "      <td>-5.303289</td>\n",
       "      <td>-3.411312</td>\n",
       "      <td>-2.900095</td>\n",
       "      <td>-4.593151</td>\n",
       "      <td>-2.870350</td>\n",
       "      <td>-2.900095</td>\n",
       "      <td>-4.562059</td>\n",
       "      <td>-3.375156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.613691</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.261353</td>\n",
       "      <td>-0.643978</td>\n",
       "      <td>-0.847538</td>\n",
       "      <td>-0.302429</td>\n",
       "      <td>-0.635943</td>\n",
       "      <td>-0.847538</td>\n",
       "      <td>-1.070465</td>\n",
       "      <td>-0.650032</td>\n",
       "      <td>-0.847538</td>\n",
       "      <td>-1.024788</td>\n",
       "      <td>-0.657205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.213942</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.554465</td>\n",
       "      <td>0.041989</td>\n",
       "      <td>-0.186079</td>\n",
       "      <td>0.754161</td>\n",
       "      <td>-0.019371</td>\n",
       "      <td>-0.186079</td>\n",
       "      <td>-0.046749</td>\n",
       "      <td>0.041118</td>\n",
       "      <td>-0.186079</td>\n",
       "      <td>0.166277</td>\n",
       "      <td>0.038561</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.148387</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.289121</td>\n",
       "      <td>0.683684</td>\n",
       "      <td>0.565310</td>\n",
       "      <td>1.647466</td>\n",
       "      <td>0.618085</td>\n",
       "      <td>0.565310</td>\n",
       "      <td>1.049437</td>\n",
       "      <td>0.715784</td>\n",
       "      <td>0.565310</td>\n",
       "      <td>1.347618</td>\n",
       "      <td>0.660219</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.523251</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.105899</td>\n",
       "      <td>3.140142</td>\n",
       "      <td>3.755152</td>\n",
       "      <td>4.404735</td>\n",
       "      <td>3.311701</td>\n",
       "      <td>3.755152</td>\n",
       "      <td>4.658191</td>\n",
       "      <td>2.651399</td>\n",
       "      <td>3.755152</td>\n",
       "      <td>5.344298</td>\n",
       "      <td>3.497461</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.775008</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               F01          F02          F03          F04          F05  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.464389     0.024135    -0.090224     0.597048    -0.019323   \n",
       "std       1.253621     0.981668     1.047949     1.525925     1.007243   \n",
       "min      -3.839055    -3.678544    -2.900095    -5.303289    -3.411312   \n",
       "25%      -0.261353    -0.643978    -0.847538    -0.302429    -0.635943   \n",
       "50%       0.554465     0.041989    -0.186079     0.754161    -0.019371   \n",
       "75%       1.289121     0.683684     0.565310     1.647466     0.618085   \n",
       "max       4.105899     3.140142     3.755152     4.404735     3.311701   \n",
       "\n",
       "               F06          F07          F08          F09          F10  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     -0.090224    -0.018502     0.017389    -0.090224     0.200876   \n",
       "std       1.047949     1.493104     0.995193     1.047949     1.649333   \n",
       "min      -2.900095    -4.593151    -2.870350    -2.900095    -4.562059   \n",
       "25%      -0.847538    -1.070465    -0.650032    -0.847538    -1.024788   \n",
       "50%      -0.186079    -0.046749     0.041118    -0.186079     0.166277   \n",
       "75%       0.565310     1.049437     0.715784     0.565310     1.347618   \n",
       "max       3.755152     4.658191     2.651399     3.755152     5.344298   \n",
       "\n",
       "               F11          F12          F14        class  \n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  \n",
       "mean      0.019299     2.481000     0.163715     0.505000  \n",
       "std       1.015434     2.280974     0.534304     0.596935  \n",
       "min      -3.375156     0.000000    -1.613691     0.000000  \n",
       "25%      -0.657205     1.000000    -0.213942     0.000000  \n",
       "50%       0.038561     2.000000     0.148387     0.000000  \n",
       "75%       0.660219     4.000000     0.523251     1.000000  \n",
       "max       3.497461     7.000000     1.775008     2.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   F01     1000 non-null   float64\n",
      " 1   F02     1000 non-null   float64\n",
      " 2   F03     1000 non-null   float64\n",
      " 3   F04     1000 non-null   float64\n",
      " 4   F05     1000 non-null   float64\n",
      " 5   F06     1000 non-null   float64\n",
      " 6   F07     1000 non-null   float64\n",
      " 7   F08     1000 non-null   float64\n",
      " 8   F09     1000 non-null   float64\n",
      " 9   F10     1000 non-null   float64\n",
      " 10  F11     1000 non-null   float64\n",
      " 11  F12     1000 non-null   int64  \n",
      " 12  F13     1000 non-null   object \n",
      " 13  F14     1000 non-null   float64\n",
      " 14  class   1000 non-null   int64  \n",
      "dtypes: float64(12), int64(2), object(1)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 2]), array(['D', 'C', 'B', 'A'], dtype=object))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"class\"].unique(), df[\"F13\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, two very important point here:\n",
    "\n",
    "1. We have 3 classes (0, 1, 2 ) and they are numerical, therefore, we need to use a multi-class method;\n",
    "2. The column F13 has categorical values, and we need to encode them before use it for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we have a not balanced dataset that we will need to work on. We have way less data for the class 2, that we have for the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    548\n",
       "1    399\n",
       "2     53\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, our data is balanced for the three values of F13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F13\n",
       "B    269\n",
       "A    253\n",
       "D    239\n",
       "C    239\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"F13\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F01</th>\n",
       "      <th>F02</th>\n",
       "      <th>F03</th>\n",
       "      <th>F04</th>\n",
       "      <th>F05</th>\n",
       "      <th>F06</th>\n",
       "      <th>F07</th>\n",
       "      <th>F08</th>\n",
       "      <th>F09</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.430770</td>\n",
       "      <td>-0.609499</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>-0.244014</td>\n",
       "      <td>1.515603</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>0.950208</td>\n",
       "      <td>-0.533577</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>-1.188635</td>\n",
       "      <td>0.117022</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.078747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.926832</td>\n",
       "      <td>-1.232067</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-2.147707</td>\n",
       "      <td>-0.907709</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-3.431166</td>\n",
       "      <td>-0.851632</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-0.614415</td>\n",
       "      <td>-0.641244</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.277881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.488724</td>\n",
       "      <td>1.732096</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>2.564819</td>\n",
       "      <td>-0.744121</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>-0.298340</td>\n",
       "      <td>-0.276540</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>1.395205</td>\n",
       "      <td>-0.290211</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.070634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        F01       F02       F03       F04       F05       F06       F07  \\\n",
       "0  0.430770 -0.609499  0.153154 -0.244014  1.515603  0.153154  0.950208   \n",
       "1  0.926832 -1.232067 -2.397645 -2.147707 -0.907709 -2.397645 -3.431166   \n",
       "2  1.488724  1.732096 -0.247872  2.564819 -0.744121 -0.247872 -0.298340   \n",
       "\n",
       "        F08       F09       F10       F11  F12  F13       F14  class  \n",
       "0 -0.533577  0.153154 -1.188635  0.117022    0  3.0  0.078747      1  \n",
       "1 -0.851632 -2.397645 -0.614415 -0.641244    0  2.0 -0.277881      1  \n",
       "2 -0.276540 -0.247872  1.395205 -0.290211    6  1.0  1.070634      0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "df_cleaned_std_caler = df.copy()\n",
    "\n",
    "categorical_cols = df_cleaned_std_caler.select_dtypes(exclude=\"number\").columns\n",
    "df_cleaned_std_caler[categorical_cols] = encoder.fit_transform(X=df_cleaned_std_caler[categorical_cols])\n",
    "\n",
    "df_cleaned_std_caler.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    548\n",
       "1    399\n",
       "2     53\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "\n",
    "ax = sns.countplot(x=\"class\", data=df_cleaned_std_caler)\n",
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Approach:\n",
    "- Let's start training a model without balancing the classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F01</th>\n",
       "      <th>F02</th>\n",
       "      <th>F03</th>\n",
       "      <th>F04</th>\n",
       "      <th>F05</th>\n",
       "      <th>F06</th>\n",
       "      <th>F07</th>\n",
       "      <th>F08</th>\n",
       "      <th>F09</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.430770</td>\n",
       "      <td>-0.609499</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>-0.244014</td>\n",
       "      <td>1.515603</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>0.950208</td>\n",
       "      <td>-0.533577</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>-1.188635</td>\n",
       "      <td>0.117022</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.078747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.926832</td>\n",
       "      <td>-1.232067</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-2.147707</td>\n",
       "      <td>-0.907709</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-3.431166</td>\n",
       "      <td>-0.851632</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-0.614415</td>\n",
       "      <td>-0.641244</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.277881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.488724</td>\n",
       "      <td>1.732096</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>2.564819</td>\n",
       "      <td>-0.744121</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>-0.298340</td>\n",
       "      <td>-0.276540</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>1.395205</td>\n",
       "      <td>-0.290211</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.070634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.476623</td>\n",
       "      <td>0.494316</td>\n",
       "      <td>0.585131</td>\n",
       "      <td>0.434526</td>\n",
       "      <td>-0.670993</td>\n",
       "      <td>0.585131</td>\n",
       "      <td>1.527264</td>\n",
       "      <td>0.370484</td>\n",
       "      <td>0.585131</td>\n",
       "      <td>-0.549108</td>\n",
       "      <td>0.009128</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.524313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.873207</td>\n",
       "      <td>-0.399677</td>\n",
       "      <td>-1.768674</td>\n",
       "      <td>0.600575</td>\n",
       "      <td>0.274092</td>\n",
       "      <td>-1.768674</td>\n",
       "      <td>-2.147604</td>\n",
       "      <td>0.623849</td>\n",
       "      <td>-1.768674</td>\n",
       "      <td>-0.387073</td>\n",
       "      <td>-0.470436</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.411954</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        F01       F02       F03       F04       F05       F06       F07  \\\n",
       "0  0.430770 -0.609499  0.153154 -0.244014  1.515603  0.153154  0.950208   \n",
       "1  0.926832 -1.232067 -2.397645 -2.147707 -0.907709 -2.397645 -3.431166   \n",
       "2  1.488724  1.732096 -0.247872  2.564819 -0.744121 -0.247872 -0.298340   \n",
       "3  0.476623  0.494316  0.585131  0.434526 -0.670993  0.585131  1.527264   \n",
       "4  1.873207 -0.399677 -1.768674  0.600575  0.274092 -1.768674 -2.147604   \n",
       "\n",
       "        F08       F09       F10       F11  F12  F13       F14  class  \n",
       "0 -0.533577  0.153154 -1.188635  0.117022    0  3.0  0.078747      1  \n",
       "1 -0.851632 -2.397645 -0.614415 -0.641244    0  2.0 -0.277881      1  \n",
       "2 -0.276540 -0.247872  1.395205 -0.290211    6  1.0  1.070634      0  \n",
       "3  0.370484  0.585131 -0.549108  0.009128    0  1.0  0.524313      1  \n",
       "4  0.623849 -1.768674 -0.387073 -0.470436    3  3.0  0.411954      2  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unbalanced = df_cleaned_std_caler.copy()\n",
    "df_unbalanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    548\n",
       "1    399\n",
       "2     53\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unbalanced[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_unbalanced.drop(\"class\", axis=1)\n",
    "y = df_unbalanced[\"class\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_clf = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(class_weight=\"balanced\", random_state=42, max_iter=1000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest F1-Score (Macro): 0.5378\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       109\n",
      "           1       0.78      0.78      0.78        80\n",
      "           2       1.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.86      0.55      0.54       200\n",
      "weighted avg       0.80      0.79      0.77       200\n",
      "\n",
      "Logistic Regression F1-Score (Macro): 0.8848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       109\n",
      "           1       0.91      0.86      0.88        80\n",
      "           2       0.77      0.91      0.83        11\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.87      0.91      0.88       200\n",
      "weighted avg       0.91      0.91      0.91       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Random Forest\n",
    "rf_f1_macro = f1_score(y_test, rf_pred, average=\"macro\")\n",
    "print(f\"Random Forest F1-Score (Macro): {rf_f1_macro:.4f}\")\n",
    "print(classification_report(y_test, rf_pred, zero_division=1))\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "lr_f1_macro = f1_score(y_test, lr_pred, average=\"macro\")\n",
    "print(f\"Logistic Regression F1-Score (Macro): {lr_f1_macro:.4f}\")\n",
    "print(classification_report(y_test, lr_pred, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `GridSearchCV for Random Forest`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "Best Parameters for Random Forest: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Best F1-Score (Macro) for Random Forest: 0.6463\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],  # Number of trees\n",
    "    \"max_depth\": [None, 10, 20],     # Depth of each tree\n",
    "    \"min_samples_split\": [2, 5, 10], # Minimum samples to split\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator = RandomForestClassifier(\n",
    "            class_weight = \"balanced\", \n",
    "            random_state = 42,\n",
    "        ),\n",
    "    param_grid = rf_param_grid,\n",
    "    scoring = \"f1_macro\",   # Optimize for f1_score_macro\n",
    "    cv = 5,                 # 5-fold cross-validation\n",
    "    verbose = 2,            # Show progress\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best Parameters for Random Forest: {rf_grid.best_params_}\")\n",
    "print(f\"Best F1-Score (Macro) for Random Forest: {rf_grid.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `GridSearchCV for Logistic Regression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END ...........................C=0.01, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...........................C=0.01, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...........................C=0.01, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...........................C=0.01, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...........................C=0.01, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............................C=0.01, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...............................C=0.01, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...............................C=0.01, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...............................C=0.01, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...............................C=0.01, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............................C=0.1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............................C=0.1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............................C=0.1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............................C=0.1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............................C=0.1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................................C=0.1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................................C=0.1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................................C=0.1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................................C=0.1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................................C=0.1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..............................C=1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............................C=1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............................C=1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............................C=1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............................C=1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................................C=1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................................C=1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................................C=1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................................C=1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................................C=1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............................C=10, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............................C=10, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............................C=10, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............................C=10, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............................C=10, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................................C=10, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .................................C=10, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .................................C=10, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .................................C=10, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .................................C=10, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............................C=100, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............................C=100, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............................C=100, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............................C=100, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............................C=100, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................................C=100, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................................C=100, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................................C=100, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................................C=100, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................................C=100, solver=lbfgs; total time=   0.0s\n",
      "Best Parameters for Logistic Regression: {'C': 100, 'solver': 'lbfgs'}\n",
      "Best F1-Score (Macro) for Logistic Regression: 0.8811\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter grid for Logistic Regression\n",
    "lr_param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1, 10, 100],      # Regularization strength\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"],  # Optimization solvers\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "lr_grid = GridSearchCV(\n",
    "    estimator=LogisticRegression(\n",
    "            class_weight = \"balanced\", \n",
    "            max_iter = 1000, \n",
    "            random_state = 42,\n",
    "        ),\n",
    "    param_grid = lr_param_grid,\n",
    "    scoring = \"f1_macro\",  # Optimize for f1_score_macro\n",
    "    cv = 5,                # 5-fold cross-validation\n",
    "    verbose = 2,            # Show progress\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "lr_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best Parameters for Logistic Regression: {lr_grid.best_params_}\")\n",
    "print(f\"Best F1-Score (Macro) for Logistic Regression: {lr_grid.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Evaluate Best Models on Test Set`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test F1-Score (Macro): 0.6334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       109\n",
      "           1       0.77      0.78      0.77        80\n",
      "           2       0.67      0.18      0.29        11\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.75      0.61      0.63       200\n",
      "weighted avg       0.79      0.80      0.78       200\n",
      "\n",
      "Logistic Regression Test F1-Score (Macro): 0.9248\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       109\n",
      "           1       0.95      0.93      0.94        80\n",
      "           2       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.92      0.94      0.92       200\n",
      "weighted avg       0.95      0.95      0.95       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best Random Forest model\n",
    "rf_best = rf_grid.best_estimator_\n",
    "rf_test_pred = rf_best.predict(X_test)\n",
    "rf_test_f1_macro = f1_score(y_test, rf_test_pred, average=\"macro\")\n",
    "print(f\"Random Forest Test F1-Score (Macro): {rf_test_f1_macro:.4f}\")\n",
    "print(classification_report(y_test, rf_test_pred, zero_division=1))\n",
    "\n",
    "# Evaluate the best Logistic Regression model\n",
    "lr_best = lr_grid.best_estimator_\n",
    "lr_test_pred = lr_best.predict(X_test)\n",
    "lr_test_f1_macro = f1_score(y_test, lr_test_pred, average=\"macro\")\n",
    "print(f\"Logistic Regression Test F1-Score (Macro): {lr_test_f1_macro:.4f}\")\n",
    "print(classification_report(y_test, lr_test_pred, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Second Approach`:\n",
    "- Let's try and see what happens for balanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F01</th>\n",
       "      <th>F02</th>\n",
       "      <th>F03</th>\n",
       "      <th>F04</th>\n",
       "      <th>F05</th>\n",
       "      <th>F06</th>\n",
       "      <th>F07</th>\n",
       "      <th>F08</th>\n",
       "      <th>F09</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.430770</td>\n",
       "      <td>-0.609499</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>-0.244014</td>\n",
       "      <td>1.515603</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>0.950208</td>\n",
       "      <td>-0.533577</td>\n",
       "      <td>0.153154</td>\n",
       "      <td>-1.188635</td>\n",
       "      <td>0.117022</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.078747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.926832</td>\n",
       "      <td>-1.232067</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-2.147707</td>\n",
       "      <td>-0.907709</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-3.431166</td>\n",
       "      <td>-0.851632</td>\n",
       "      <td>-2.397645</td>\n",
       "      <td>-0.614415</td>\n",
       "      <td>-0.641244</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.277881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.488724</td>\n",
       "      <td>1.732096</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>2.564819</td>\n",
       "      <td>-0.744121</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>-0.298340</td>\n",
       "      <td>-0.276540</td>\n",
       "      <td>-0.247872</td>\n",
       "      <td>1.395205</td>\n",
       "      <td>-0.290211</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.070634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.476623</td>\n",
       "      <td>0.494316</td>\n",
       "      <td>0.585131</td>\n",
       "      <td>0.434526</td>\n",
       "      <td>-0.670993</td>\n",
       "      <td>0.585131</td>\n",
       "      <td>1.527264</td>\n",
       "      <td>0.370484</td>\n",
       "      <td>0.585131</td>\n",
       "      <td>-0.549108</td>\n",
       "      <td>0.009128</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.524313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.873207</td>\n",
       "      <td>-0.399677</td>\n",
       "      <td>-1.768674</td>\n",
       "      <td>0.600575</td>\n",
       "      <td>0.274092</td>\n",
       "      <td>-1.768674</td>\n",
       "      <td>-2.147604</td>\n",
       "      <td>0.623849</td>\n",
       "      <td>-1.768674</td>\n",
       "      <td>-0.387073</td>\n",
       "      <td>-0.470436</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.411954</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        F01       F02       F03       F04       F05       F06       F07  \\\n",
       "0  0.430770 -0.609499  0.153154 -0.244014  1.515603  0.153154  0.950208   \n",
       "1  0.926832 -1.232067 -2.397645 -2.147707 -0.907709 -2.397645 -3.431166   \n",
       "2  1.488724  1.732096 -0.247872  2.564819 -0.744121 -0.247872 -0.298340   \n",
       "3  0.476623  0.494316  0.585131  0.434526 -0.670993  0.585131  1.527264   \n",
       "4  1.873207 -0.399677 -1.768674  0.600575  0.274092 -1.768674 -2.147604   \n",
       "\n",
       "        F08       F09       F10       F11  F12  F13       F14  class  \n",
       "0 -0.533577  0.153154 -1.188635  0.117022    0  3.0  0.078747      1  \n",
       "1 -0.851632 -2.397645 -0.614415 -0.641244    0  2.0 -0.277881      1  \n",
       "2 -0.276540 -0.247872  1.395205 -0.290211    6  1.0  1.070634      0  \n",
       "3  0.370484  0.585131 -0.549108  0.009128    0  1.0  0.524313      1  \n",
       "4  0.623849 -1.768674 -0.387073 -0.470436    3  3.0  0.411954      2  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = df_cleaned_std_caler.copy()\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separate features and target\n",
    "X = df_balanced.drop(labels=\"class\", axis=1)\n",
    "y = df_balanced[\"class\"]\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER applying SMOTE to balance the data:\n",
      "\tX: (rows, columns) = (1644, 14)\n",
      "\ty: (rows, columns) = (1644,)\n"
     ]
    }
   ],
   "source": [
    "X_rows, X_column = X_resampled.shape\n",
    "print(f\"AFTER applying SMOTE to balance the data:\")\n",
    "print(f\"\\tX: (rows, columns) = ({X_rows}, {X_column})\")\n",
    "print(f\"\\ty: (rows, columns) = {y_resampled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced_final = pd.concat([X_resampled, y_resampled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    548\n",
       "0    548\n",
       "2    548\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGwCAYAAABPSaTdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiZ0lEQVR4nO3de3BU9f3/8dfmtgkkmzSB7JKSRKwoRLm0AcNWSxVTImYYGTJeGAYiIipuaCEVaWa4I8bSVhANoA4CTqVY7KAVEQNBQoUEMBCLIBQZNHRgEwSTQDQXkvz+6LA/9xvwkizZ5cPzMbMz7Dmf3X2fznZ8zp6zG0tra2urAAAADBXk7wEAAACuJGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYL8fcAgaClpUUnT55UVFSULBaLv8cBAAA/QGtrq86dO6eEhAQFBV3+8xtiR9LJkyeVmJjo7zEAAEA7nDhxQj179rzsfmJHUlRUlKT//Y9ls9n8PA0AAPghamtrlZiY6Pnv+OUQO5Ln1JXNZiN2AAC4ynzfJShcoAwAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGgh/h7AFKnTX/P3CAggZX8a7+8RJPG+hLdAeF/ynsS3ddZ7kk92AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNL/Gzty5c2WxWLxuffr08eyvr6+Xy+VSXFycIiMjlZWVpcrKSq/nqKioUGZmprp06aL4+HhNnz5dFy5c6OxDAQAAASrE3wPcfPPN2rp1q+d+SMj/H2natGl69913tX79ekVHRysnJ0ejR4/Wzp07JUnNzc3KzMyUw+HQrl27dOrUKY0fP16hoaF65plnOv1YAABA4PF77ISEhMjhcLTZXlNTo5UrV2rt2rUaNmyYJGnVqlXq27evSktLNWTIEBUWFurQoUPaunWr7Ha7Bg4cqAULFmjGjBmaO3euwsLCOvtwAABAgPH7NTtHjx5VQkKCrr/+eo0dO1YVFRWSpLKyMjU1NSk9Pd2ztk+fPkpKSlJJSYkkqaSkRP369ZPdbvesycjIUG1trQ4ePHjZ12xoaFBtba3XDQAAmMmvsZOWlqbVq1dr8+bNWr58uY4fP65f/epXOnfunNxut8LCwhQTE+P1GLvdLrfbLUlyu91eoXNx/8V9l5Ofn6/o6GjPLTEx0bcHBgAAAoZfT2ONGDHC8+/+/fsrLS1NycnJ+vvf/66IiIgr9rp5eXnKzc313K+trSV4AAAwlN9PY31bTEyMbrzxRn322WdyOBxqbGxUdXW115rKykrPNT4Oh6PNt7Mu3r/UdUAXWa1W2Ww2rxsAADBTQMXO+fPndezYMfXo0UOpqakKDQ1VUVGRZ/+RI0dUUVEhp9MpSXI6nTpw4ICqqqo8a7Zs2SKbzaaUlJROnx8AAAQev57GevLJJzVy5EglJyfr5MmTmjNnjoKDgzVmzBhFR0dr4sSJys3NVWxsrGw2m6ZMmSKn06khQ4ZIkoYPH66UlBSNGzdOixYtktvt1syZM+VyuWS1Wv15aAAAIED4NXb++9//asyYMTpz5oy6d++u22+/XaWlperevbskafHixQoKClJWVpYaGhqUkZGhZcuWeR4fHBysjRs3avLkyXI6neratauys7M1f/58fx0SAAAIMH6NnXXr1n3n/vDwcBUUFKigoOCya5KTk7Vp0yZfjwYAAAwRUNfsAAAA+BqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwWsDEzrPPPiuLxaKpU6d6ttXX18vlcikuLk6RkZHKyspSZWWl1+MqKiqUmZmpLl26KD4+XtOnT9eFCxc6eXoAABCoAiJ29u7dq5deekn9+/f32j5t2jS98847Wr9+vYqLi3Xy5EmNHj3as7+5uVmZmZlqbGzUrl27tGbNGq1evVqzZ8/u7EMAAAAByu+xc/78eY0dO1avvPKKfvKTn3i219TUaOXKlXruuec0bNgwpaamatWqVdq1a5dKS0slSYWFhTp06JD++te/auDAgRoxYoQWLFiggoICNTY2+uuQAABAAPF77LhcLmVmZio9Pd1re1lZmZqamry29+nTR0lJSSopKZEklZSUqF+/frLb7Z41GRkZqq2t1cGDBy/7mg0NDaqtrfW6AQAAM4X488XXrVunffv2ae/evW32ud1uhYWFKSYmxmu73W6X2+32rPl26Fzcf3Hf5eTn52vevHkdnB4AAFwN/PbJzokTJ/S73/1Or7/+usLDwzv1tfPy8lRTU+O5nThxolNfHwAAdB6/xU5ZWZmqqqr0i1/8QiEhIQoJCVFxcbGWLl2qkJAQ2e12NTY2qrq62utxlZWVcjgckiSHw9Hm21kX719ccylWq1U2m83rBgAAzOS32Lnrrrt04MABlZeXe26DBg3S2LFjPf8ODQ1VUVGR5zFHjhxRRUWFnE6nJMnpdOrAgQOqqqryrNmyZYtsNptSUlI6/ZgAAEDg8ds1O1FRUbrlllu8tnXt2lVxcXGe7RMnTlRubq5iY2Nls9k0ZcoUOZ1ODRkyRJI0fPhwpaSkaNy4cVq0aJHcbrdmzpwpl8slq9Xa6ccEAAACj18vUP4+ixcvVlBQkLKystTQ0KCMjAwtW7bMsz84OFgbN27U5MmT5XQ61bVrV2VnZ2v+/Pl+nBoAAASSgIqd7du3e90PDw9XQUGBCgoKLvuY5ORkbdq06QpPBgAArlZ+/50dAACAK4nYAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYLR2xc6wYcNUXV3dZnttba2GDRvW0ZkAAAB8pl2xs337djU2NrbZXl9fr3/9618dHgoAAMBXQn7M4n//+9+efx86dEhut9tzv7m5WZs3b9ZPf/pT300HAADQQT8qdgYOHCiLxSKLxXLJ01URERF64YUXfDYcAABAR/2o2Dl+/LhaW1t1/fXXa8+ePerevbtnX1hYmOLj4xUcHOzzIQEAANrrR12zk5ycrOuuu04tLS0aNGiQkpOTPbcePXr86NBZvny5+vfvL5vNJpvNJqfTqffee8+zv76+Xi6XS3FxcYqMjFRWVpYqKyu9nqOiokKZmZnq0qWL4uPjNX36dF24cOFHzQEAAMz1oz7Z+bajR4/qgw8+UFVVlVpaWrz2zZ49+wc9R8+ePfXss8+qd+/eam1t1Zo1a3Tvvfdq//79uvnmmzVt2jS9++67Wr9+vaKjo5WTk6PRo0dr586dkv53nVBmZqYcDod27dqlU6dOafz48QoNDdUzzzzT3kMDAAAGaVfsvPLKK5o8ebK6desmh8Mhi8Xi2WexWH5w7IwcOdLr/sKFC7V8+XKVlpaqZ8+eWrlypdauXeu5PmjVqlXq27evSktLNWTIEBUWFurQoUPaunWr7Ha7Bg4cqAULFmjGjBmaO3euwsLC2nN4AADAIO366vnTTz+thQsXyu12q7y8XPv37/fc9u3b165BmpubtW7dOtXV1cnpdKqsrExNTU1KT0/3rOnTp4+SkpJUUlIiSSopKVG/fv1kt9s9azIyMlRbW6uDBw9e9rUaGhpUW1vrdQMAAGZqV+x89dVXuu+++3wywIEDBxQZGSmr1arHH39cGzZsUEpKitxut8LCwhQTE+O13m63e77y7na7vULn4v6L+y4nPz9f0dHRnltiYqJPjgUAAASedsXOfffdp8LCQp8McNNNN6m8vFy7d+/W5MmTlZ2drUOHDvnkuS8nLy9PNTU1ntuJEyeu6OsBAAD/adc1OzfccINmzZql0tJS9evXT6GhoV77f/vb3/7g5woLC9MNN9wgSUpNTdXevXv1/PPP64EHHlBjY6Oqq6u9Pt2prKyUw+GQJDkcDu3Zs8fr+S5+W+vimkuxWq2yWq0/eEYAAHD1alfsvPzyy4qMjFRxcbGKi4u99lkslh8VO/9XS0uLGhoalJqaqtDQUBUVFSkrK0uSdOTIEVVUVMjpdEqSnE6nFi5cqKqqKsXHx0uStmzZIpvNppSUlHbPAAAAzNGu2Dl+/LhPXjwvL08jRoxQUlKSzp07p7Vr12r79u16//33FR0drYkTJyo3N1exsbGy2WyaMmWKnE6nhgwZIkkaPny4UlJSNG7cOC1atEhut1szZ86Uy+XikxsAACCpA7+z4wtVVVUaP368Tp06pejoaPXv31/vv/++fvOb30iSFi9erKCgIGVlZamhoUEZGRlatmyZ5/HBwcHauHGjJk+eLKfTqa5duyo7O1vz58/31yEBAIAA067Yefjhh79z/6uvvvqDnmflypXfuT88PFwFBQUqKCi47Jrk5GRt2rTpB70eAAC49rQrdr766iuv+01NTfrkk09UXV19yT8QCgAA4C/tip0NGza02dbS0qLJkyfrZz/7WYeHAgAA8JV2/c7OJZ8oKEi5ublavHixr54SAACgw3wWO5J07Ngx/uI4AAAIKO06jZWbm+t1v7W1VadOndK7776r7OxsnwwGAADgC+2Knf3793vdDwoKUvfu3fWXv/zle7+pBQAA0JnaFTsffPCBr+cAAAC4Ijr0o4KnT5/WkSNHJP3vD3p2797dJ0MBAAD4SrsuUK6rq9PDDz+sHj16aOjQoRo6dKgSEhI0ceJEff31176eEQAAoN3aFTu5ubkqLi7WO++8o+rqalVXV+vtt99WcXGxfv/73/t6RgAAgHZr12msf/zjH3rzzTd1xx13eLbdc889ioiI0P3336/ly5f7aj4AAIAOadcnO19//bXsdnub7fHx8ZzGAgAAAaVdseN0OjVnzhzV19d7tn3zzTeaN2+enE6nz4YDAADoqHadxlqyZInuvvtu9ezZUwMGDJAkffzxx7JarSosLPTpgAAAAB3Rrtjp16+fjh49qtdff12HDx+WJI0ZM0Zjx45VRESETwcEAADoiHbFTn5+vux2uyZNmuS1/dVXX9Xp06c1Y8YMnwwHAADQUe26Zuell15Snz592my/+eabtWLFig4PBQAA4Cvtih23260ePXq02d69e3edOnWqw0MBAAD4SrtiJzExUTt37myzfefOnUpISOjwUAAAAL7Srmt2Jk2apKlTp6qpqUnDhg2TJBUVFempp57iF5QBAEBAaVfsTJ8+XWfOnNETTzyhxsZGSVJ4eLhmzJihvLw8nw4IAADQEe2KHYvFoj/+8Y+aNWuWPv30U0VERKh3796yWq2+ng8AAKBD2hU7F0VGRmrw4MG+mgUAAMDn2nWBMgAAwNWC2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0fwaO/n5+Ro8eLCioqIUHx+vUaNG6ciRI15r6uvr5XK5FBcXp8jISGVlZamystJrTUVFhTIzM9WlSxfFx8dr+vTpunDhQmceCgAACFB+jZ3i4mK5XC6VlpZqy5Ytampq0vDhw1VXV+dZM23aNL3zzjtav369iouLdfLkSY0ePdqzv7m5WZmZmWpsbNSuXbu0Zs0arV69WrNnz/bHIQEAgAAT4s8X37x5s9f91atXKz4+XmVlZRo6dKhqamq0cuVKrV27VsOGDZMkrVq1Sn379lVpaamGDBmiwsJCHTp0SFu3bpXdbtfAgQO1YMECzZgxQ3PnzlVYWFib121oaFBDQ4Pnfm1t7ZU9UAAA4DcBdc1OTU2NJCk2NlaSVFZWpqamJqWnp3vW9OnTR0lJSSopKZEklZSUqF+/frLb7Z41GRkZqq2t1cGDBy/5Ovn5+YqOjvbcEhMTr9QhAQAAPwuY2GlpadHUqVN122236ZZbbpEkud1uhYWFKSYmxmut3W6X2+32rPl26Fzcf3HfpeTl5ammpsZzO3HihI+PBgAABAq/nsb6NpfLpU8++UQffvjhFX8tq9Uqq9V6xV8HAAD4X0B8spOTk6ONGzfqgw8+UM+ePT3bHQ6HGhsbVV1d7bW+srJSDofDs+b/fjvr4v2LawAAwLXLr7HT2tqqnJwcbdiwQdu2bVOvXr289qempio0NFRFRUWebUeOHFFFRYWcTqckyel06sCBA6qqqvKs2bJli2w2m1JSUjrnQAAAQMDy62ksl8ultWvX6u2331ZUVJTnGpvo6GhFREQoOjpaEydOVG5urmJjY2Wz2TRlyhQ5nU4NGTJEkjR8+HClpKRo3LhxWrRokdxut2bOnCmXy8WpKgAA4N/YWb58uSTpjjvu8Nq+atUqPfTQQ5KkxYsXKygoSFlZWWpoaFBGRoaWLVvmWRscHKyNGzdq8uTJcjqd6tq1q7KzszV//vzOOgwAABDA/Bo7ra2t37smPDxcBQUFKigouOya5ORkbdq0yZejAQAAQwTEBcoAAABXCrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADCaX2Nnx44dGjlypBISEmSxWPTWW2957W9tbdXs2bPVo0cPRUREKD09XUePHvVac/bsWY0dO1Y2m00xMTGaOHGizp8/34lHAQAAAplfY6eurk4DBgxQQUHBJfcvWrRIS5cu1YoVK7R792517dpVGRkZqq+v96wZO3asDh48qC1btmjjxo3asWOHHn300c46BAAAEOBC/PniI0aM0IgRIy65r7W1VUuWLNHMmTN17733SpJee+012e12vfXWW3rwwQf16aefavPmzdq7d68GDRokSXrhhRd0zz336M9//rMSEhIu+dwNDQ1qaGjw3K+trfXxkQEAgEARsNfsHD9+XG63W+np6Z5t0dHRSktLU0lJiSSppKREMTExntCRpPT0dAUFBWn37t2Xfe78/HxFR0d7bomJiVfuQAAAgF8FbOy43W5Jkt1u99put9s9+9xut+Lj4732h4SEKDY21rPmUvLy8lRTU+O5nThxwsfTAwCAQOHX01j+YrVaZbVa/T0GAADoBAH7yY7D4ZAkVVZWem2vrKz07HM4HKqqqvLaf+HCBZ09e9azBgAAXNsCNnZ69eolh8OhoqIiz7ba2lrt3r1bTqdTkuR0OlVdXa2ysjLPmm3btqmlpUVpaWmdPjMAAAg8fj2Ndf78eX322Wee+8ePH1d5ebliY2OVlJSkqVOn6umnn1bv3r3Vq1cvzZo1SwkJCRo1apQkqW/fvrr77rs1adIkrVixQk1NTcrJydGDDz542W9iAQCAa4tfY+ejjz7SnXfe6bmfm5srScrOztbq1av11FNPqa6uTo8++qiqq6t1++23a/PmzQoPD/c85vXXX1dOTo7uuusuBQUFKSsrS0uXLu30YwEAAIHJr7Fzxx13qLW19bL7LRaL5s+fr/nz5192TWxsrNauXXslxgMAAAYI2Gt2AAAAfIHYAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYjdgBAABGI3YAAIDRiB0AAGA0YgcAABiN2AEAAEYjdgAAgNGIHQAAYDRiBwAAGI3YAQAARiN2AACA0YgdAABgNGIHAAAYzZjYKSgo0HXXXafw8HClpaVpz549/h4JAAAEACNi54033lBubq7mzJmjffv2acCAAcrIyFBVVZW/RwMAAH5mROw899xzmjRpkiZMmKCUlBStWLFCXbp00auvvurv0QAAgJ+F+HuAjmpsbFRZWZny8vI824KCgpSenq6SkpJLPqahoUENDQ2e+zU1NZKk2trads/R3PBNux8L83TkveRLvC/xbYHwvuQ9iW/r6Hvy4uNbW1u/c91VHztffvmlmpubZbfbvbbb7XYdPnz4ko/Jz8/XvHnz2mxPTEy8IjPi2hP9wuP+HgFog/clAo2v3pPnzp1TdHT0Zfdf9bHTHnl5ecrNzfXcb2lp0dmzZxUXFyeLxeLHya5utbW1SkxM1IkTJ2Sz2fw9DiCJ9yUCD+9J32ltbdW5c+eUkJDwneuu+tjp1q2bgoODVVlZ6bW9srJSDofjko+xWq2yWq1e22JiYq7UiNccm83G/4ERcHhfItDwnvSN7/pE56Kr/gLlsLAwpaamqqioyLOtpaVFRUVFcjqdfpwMAAAEgqv+kx1Jys3NVXZ2tgYNGqRbb71VS5YsUV1dnSZMmODv0QAAgJ8ZETsPPPCATp8+rdmzZ8vtdmvgwIHavHlzm4uWcWVZrVbNmTOnzSlCwJ94XyLQ8J7sfJbW7/u+FgAAwFXsqr9mBwAA4LsQOwAAwGjEDgAAMBqxAwAAjEbswGcKCgp03XXXKTw8XGlpadqzZ4+/R8I1bMeOHRo5cqQSEhJksVj01ltv+XskXOPy8/M1ePBgRUVFKT4+XqNGjdKRI0f8PdY1gdiBT7zxxhvKzc3VnDlztG/fPg0YMEAZGRmqqqry92i4RtXV1WnAgAEqKCjw9yiAJKm4uFgul0ulpaXasmWLmpqaNHz4cNXV1fl7NOPx1XP4RFpamgYPHqwXX3xR0v9+xToxMVFTpkzRH/7wBz9Ph2udxWLRhg0bNGrUKH+PAnicPn1a8fHxKi4u1tChQ/09jtH4ZAcd1tjYqLKyMqWnp3u2BQUFKT09XSUlJX6cDAACV01NjSQpNjbWz5OYj9hBh3355Zdqbm5u84vVdrtdbrfbT1MBQOBqaWnR1KlTddttt+mWW27x9zjGM+LPRQAAcDVxuVz65JNP9OGHH/p7lGsCsYMO69atm4KDg1VZWem1vbKyUg6Hw09TAUBgysnJ0caNG7Vjxw717NnT3+NcEziNhQ4LCwtTamqqioqKPNtaWlpUVFQkp9Ppx8kAIHC0trYqJydHGzZs0LZt29SrVy9/j3TN4JMd+ERubq6ys7M1aNAg3XrrrVqyZInq6uo0YcIEf4+Ga9T58+f12Wefee4fP35c5eXlio2NVVJSkh8nw7XK5XJp7dq1evvttxUVFeW5pjE6OloRERF+ns5sfPUcPvPiiy/qT3/6k9xutwYOHKilS5cqLS3N32PhGrV9+3bdeeedbbZnZ2dr9erVnT8QrnkWi+WS21etWqWHHnqoc4e5xhA7AADAaFyzAwAAjEbsAAAAoxE7AADAaMQOAAAwGrEDAACMRuwAAACjETsAAMBoxA4AADAasQPgqvX555/LYrGovLzc36MACGDEDgAAMBqxAwAAjEbsAAh4LS0tWrRokW644QZZrVYlJSVp4cKFbdY1Nzdr4sSJ6tWrlyIiInTTTTfp+eef91qzfft23XrrreratatiYmJ022236YsvvpAkffzxx7rzzjsVFRUlm82m1NRUffTRR51yjACunBB/DwAA3ycvL0+vvPKKFi9erNtvv12nTp3S4cOH26xraWlRz549tX79esXFxWnXrl169NFH1aNHD91///26cOGCRo0apUmTJulvf/ubGhsbtWfPHs9fox47dqx+/vOfa/ny5QoODlZ5eblCQ0M7+3AB+Bh/9RxAQDt37py6d++uF198UY888ojXvs8//1y9evXS/v37NXDgwEs+PicnR263W2+++abOnj2ruLg4bd++Xb/+9a/brLXZbHrhhReUnZ19JQ4FgJ9wGgtAQPv000/V0NCgu+666wetLygoUGpqqrp3767IyEi9/PLLqqiokCTFxsbqoYceUkZGhkaOHKnnn39ep06d8jw2NzdXjzzyiNLT0/Xss8/q2LFjV+SYAHQuYgdAQIuIiPjBa9etW6cnn3xSEydOVGFhocrLyzVhwgQ1NjZ61qxatUolJSX65S9/qTfeeEM33nijSktLJUlz587VwYMHlZmZqW3btiklJUUbNmzw+TEB6FycxgIQ0Orr6xUbG6ulS5d+72msKVOm6NChQyoqKvKsSU9P15dffnnZ3+JxOp0aPHiwli5d2mbfmDFjVFdXp3/+858+PSYAnYtPdgAEtPDwcM2YMUNPPfWUXnvtNR07dkylpaVauXJlm7W9e/fWRx99pPfff1//+c9/NGvWLO3du9ez//jx48rLy1NJSYm++OILFRYW6ujRo+rbt6+++eYb5eTkaPv27friiy+0c+dO7d27V3379u3MwwVwBfBtLAABb9asWQoJCdHs2bN18uRJ9ejRQ48//nibdY899pj279+vBx54QBaLRWPGjNETTzyh9957T5LUpUsXHT58WGvWrNGZM2fUo0cPuVwuPfbYY7pw4YLOnDmj8ePHq7KyUt26ddPo0aM1b968zj5cAD7GaSwAAGA0TmMBAACjETsAAMBoxA4AADAasQMAAIxG7AAAAKMROwAAwGjEDgAAMBqxAwAAjEbsAAAAoxE7AADAaMQOAAAw2v8DzfXAEo5g+kQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x=\"class\", data=df_balanced_final)\n",
    "df_balanced_final[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1644 entries, 0 to 1643\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   F01     1644 non-null   float64\n",
      " 1   F02     1644 non-null   float64\n",
      " 2   F03     1644 non-null   float64\n",
      " 3   F04     1644 non-null   float64\n",
      " 4   F05     1644 non-null   float64\n",
      " 5   F06     1644 non-null   float64\n",
      " 6   F07     1644 non-null   float64\n",
      " 7   F08     1644 non-null   float64\n",
      " 8   F09     1644 non-null   float64\n",
      " 9   F10     1644 non-null   float64\n",
      " 10  F11     1644 non-null   float64\n",
      " 11  F12     1644 non-null   int64  \n",
      " 12  F13     1644 non-null   float64\n",
      " 13  F14     1644 non-null   float64\n",
      " 14  class   1644 non-null   int64  \n",
      "dtypes: float64(13), int64(2)\n",
      "memory usage: 192.8 KB\n"
     ]
    }
   ],
   "source": [
    "df_balanced_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_balanced_final.drop(\"class\", axis=1)\n",
    "y = df_balanced_final[\"class\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifiers  with Class Weights:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_clf = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(class_weight=\"balanced\", random_state=42, max_iter=1000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate with F1-Score (Macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest F1-Score (Macro): 0.8835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84       109\n",
      "           1       0.82      0.85      0.84       110\n",
      "           2       0.96      0.99      0.97       110\n",
      "\n",
      "    accuracy                           0.88       329\n",
      "   macro avg       0.88      0.88      0.88       329\n",
      "weighted avg       0.88      0.88      0.88       329\n",
      "\n",
      "Logistic Regression F1-Score (Macro): 0.9423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       109\n",
      "           1       0.91      0.92      0.91       110\n",
      "           2       0.96      0.97      0.97       110\n",
      "\n",
      "    accuracy                           0.94       329\n",
      "   macro avg       0.94      0.94      0.94       329\n",
      "weighted avg       0.94      0.94      0.94       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Random Forest\n",
    "rf_f1_macro = f1_score(y_test, rf_pred, average=\"macro\")\n",
    "print(f\"Random Forest F1-Score (Macro): {rf_f1_macro:.4f}\")\n",
    "print(classification_report(y_test, rf_pred, zero_division=1))\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "lr_f1_macro = f1_score(y_test, lr_pred, average=\"macro\")\n",
    "print(f\"Logistic Regression F1-Score (Macro): {lr_f1_macro:.4f}\")\n",
    "print(classification_report(y_test, lr_pred, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Applying GridSearchCV`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=10, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=20, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END .max_depth=20, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=200; total time=   0.2s\n",
      "Best Parameters for Random Forest: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best F1-Score (Macro) for Random Forest: 0.9089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],  # Number of trees\n",
    "    \"max_depth\": [None, 10, 20],     # Depth of each tree\n",
    "    \"min_samples_split\": [2, 5, 10], # Minimum samples to split\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(class_weight=\"balanced\", random_state=42),\n",
    "    param_grid=rf_param_grid,\n",
    "    scoring=\"f1_macro\",  # Optimize for f1_score_macro\n",
    "    cv=5,                # 5-fold cross-validation\n",
    "    verbose=2            # Show progress\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best Parameters for Random Forest: {rf_grid.best_params_}\")\n",
    "print(f\"Best F1-Score (Macro) for Random Forest: {rf_grid.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END ...........................C=0.01, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...........................C=0.01, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...........................C=0.01, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...........................C=0.01, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...........................C=0.01, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............................C=0.01, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...............................C=0.01, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...............................C=0.01, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...............................C=0.01, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...............................C=0.01, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............................C=0.1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............................C=0.1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............................C=0.1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............................C=0.1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............................C=0.1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................................C=0.1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................................C=0.1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................................C=0.1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................................C=0.1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................................C=0.1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..............................C=1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............................C=1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............................C=1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............................C=1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............................C=1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................................C=1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................................C=1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................................C=1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................................C=1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................................C=1, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .............................C=10, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............................C=10, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............................C=10, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............................C=10, solver=liblinear; total time=   0.0s\n",
      "[CV] END .............................C=10, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................................C=10, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .................................C=10, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .................................C=10, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .................................C=10, solver=lbfgs; total time=   0.0s\n",
      "[CV] END .................................C=10, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ............................C=100, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............................C=100, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............................C=100, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............................C=100, solver=liblinear; total time=   0.0s\n",
      "[CV] END ............................C=100, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................................C=100, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................................C=100, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................................C=100, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................................C=100, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................................C=100, solver=lbfgs; total time=   0.0s\n",
      "Best Parameters for Logistic Regression: {'C': 100, 'solver': 'lbfgs'}\n",
      "Best F1-Score (Macro) for Logistic Regression: 0.9543\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter grid for Logistic Regression\n",
    "lr_param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1, 10, 100],      # Regularization strength\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"],  # Optimization solvers\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "lr_grid = GridSearchCV(\n",
    "    estimator=LogisticRegression(class_weight=\"balanced\", max_iter=1000, random_state=42),\n",
    "    param_grid=lr_param_grid,\n",
    "    scoring=\"f1_macro\",  # Optimize for f1_score_macro\n",
    "    cv=5,                # 5-fold cross-validation\n",
    "    verbose=2            # Show progress\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "lr_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best Parameters for Logistic Regression: {lr_grid.best_params_}\")\n",
    "print(f\"Best F1-Score (Macro) for Logistic Regression: {lr_grid.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test F1-Score (Macro): 0.8905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85       109\n",
      "           1       0.83      0.85      0.84       110\n",
      "           2       0.98      0.98      0.98       110\n",
      "\n",
      "    accuracy                           0.89       329\n",
      "   macro avg       0.89      0.89      0.89       329\n",
      "weighted avg       0.89      0.89      0.89       329\n",
      "\n",
      "Logistic Regression Test F1-Score (Macro): 0.9484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       109\n",
      "           1       0.92      0.93      0.92       110\n",
      "           2       0.97      0.96      0.97       110\n",
      "\n",
      "    accuracy                           0.95       329\n",
      "   macro avg       0.95      0.95      0.95       329\n",
      "weighted avg       0.95      0.95      0.95       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best Random Forest model\n",
    "rf_best = rf_grid.best_estimator_\n",
    "rf_test_pred = rf_best.predict(X_test)\n",
    "rf_test_f1_macro = f1_score(y_test, rf_test_pred, average=\"macro\")\n",
    "print(f\"Random Forest Test F1-Score (Macro): {rf_test_f1_macro:.4f}\")\n",
    "print(classification_report(y_test, rf_test_pred, zero_division=1))\n",
    "\n",
    "# Evaluate the best Logistic Regression model\n",
    "lr_best = lr_grid.best_estimator_\n",
    "lr_test_pred = lr_best.predict(X_test)\n",
    "lr_test_f1_macro = f1_score(y_test, lr_test_pred, average=\"macro\")\n",
    "print(f\"Logistic Regression Test F1-Score (Macro): {lr_test_f1_macro:.4f}\")\n",
    "print(classification_report(y_test, lr_test_pred, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the F1-Score (Macro) get much better for a balanced dataset.\n",
    "\n",
    "`Unbalanced`:\n",
    ">    - Random Forest: 0.6334\n",
    ">    - Logistic Regression: 0.9248\n",
    "\n",
    "`Balanced`:\n",
    ">    - Random Forest: 0.8905\n",
    ">    - Logistic Regression: 0.9484\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Feature Selection with RFE (Recursive Feature Elimination)`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `RFE for Random Forest`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features for Random Forest: ['F02', 'F04', 'F07', 'F10', 'F14']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Initialize RFE with the best Random Forest model\n",
    "rfe_rf = RFE(estimator=rf_best, n_features_to_select=5, step=1)  # Select top 5 features\n",
    "rfe_rf.fit(X_train, y_train)\n",
    "\n",
    "# Selected features\n",
    "selected_features_rf = X_train.columns[rfe_rf.support_]\n",
    "print(f\"Selected Features for Random Forest: {list(selected_features_rf)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `RFE for Logistic Regression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features for Logistic Regression: ['F02', 'F07', 'F10', 'F11', 'F14']\n"
     ]
    }
   ],
   "source": [
    "# Initialize RFE with the best Logistic Regression model\n",
    "rfe_lr = RFE(estimator=lr_best, n_features_to_select=5, step=1)  # Select top 5 features\n",
    "rfe_lr.fit(X_train, y_train)\n",
    "\n",
    "# Selected features\n",
    "selected_features_lr = X_train.columns[rfe_lr.support_]\n",
    "print(f\"Selected Features for Logistic Regression: {list(selected_features_lr)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Train and Test with Selected Features`:\n",
    "\n",
    "- Once the top features are selected, train and evaluate the models using only these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate Random Forest with Selected Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest F1-Score (Macro) with Selected Features: 0.9054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       109\n",
      "           1       0.86      0.85      0.86       110\n",
      "           2       0.95      0.97      0.96       110\n",
      "\n",
      "    accuracy                           0.91       329\n",
      "   macro avg       0.91      0.91      0.91       329\n",
      "weighted avg       0.91      0.91      0.91       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subset data with selected features\n",
    "X_train_rf_selected = X_train[selected_features_rf]\n",
    "X_test_rf_selected = X_test[selected_features_rf]\n",
    "\n",
    "# Train with the best Random Forest model\n",
    "rf_best.fit(X_train_rf_selected, y_train)\n",
    "rf_pred_selected = rf_best.predict(X_test_rf_selected)\n",
    "\n",
    "# Evaluate\n",
    "rf_f1_macro_selected = f1_score(y_test, rf_pred_selected, average=\"macro\")\n",
    "print(f\"Random Forest F1-Score (Macro) with Selected Features: {rf_f1_macro_selected:.4f}\")\n",
    "print(classification_report(y_test, rf_pred_selected, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate Logistic Regression with Selected Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1-Score (Macro) with Selected Features: 0.9454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       109\n",
      "           1       0.91      0.93      0.92       110\n",
      "           2       0.97      0.96      0.97       110\n",
      "\n",
      "    accuracy                           0.95       329\n",
      "   macro avg       0.95      0.95      0.95       329\n",
      "weighted avg       0.95      0.95      0.95       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subset data with selected features\n",
    "X_train_lr_selected = X_train[selected_features_lr]\n",
    "X_test_lr_selected = X_test[selected_features_lr]\n",
    "\n",
    "# Train with the best Logistic Regression model\n",
    "lr_best.fit(X_train_lr_selected, y_train)\n",
    "lr_pred_selected = lr_best.predict(X_test_lr_selected)\n",
    "\n",
    "# Evaluate\n",
    "lr_f1_macro_selected = f1_score(y_test, lr_pred_selected, average=\"macro\")\n",
    "print(f\"Logistic Regression F1-Score (Macro) with Selected Features: {lr_f1_macro_selected:.4f}\")\n",
    "print(classification_report(y_test, lr_pred_selected, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the F1-Score (Macro) increases for Random Forest, but decreases for Logistic Regression.\n",
    "\n",
    "`Before RFE`:\n",
    ">    - Random Forest: 0.8905\n",
    ">    - Logistic Regression: 0.9484\n",
    "    \n",
    "`After RFE`:\n",
    ">    - Random Forest: 0.9054\n",
    ">    - Logistic Regression: 0.9454"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance for Random Forest (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['F02', 'F04', 'F07', 'F10', 'F14'], dtype='object')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = rf_best.feature_importances_\n",
    "X_train_rf_selected.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Importance\n",
      "4     F14    0.253034\n",
      "3     F10    0.199710\n",
      "0     F02    0.187213\n",
      "2     F07    0.185144\n",
      "1     F04    0.174899\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances\n",
    "importances = rf_best.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"Feature\": X_train_rf_selected.columns,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Display top features\n",
    "print(feature_importance_df.head(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
